FROM nvcr.io/nvidia/l4t-jetpack:r35.4.1

WORKDIR /charlie

RUN echo "deb [arch=arm64] http://ports.ubuntu.com/ubuntu-ports focal main restricted universe multiverse" > /etc/apt/sources.list && \
    echo "deb [arch=arm64] http://ports.ubuntu.com/ubuntu-ports focal-updates main restricted universe multiverse" >> /etc/apt/sources.list && \
    echo "deb [arch=arm64] http://ports.ubuntu.com/ubuntu-ports focal-security main restricted universe multiverse" >> /etc/apt/sources.list && \
    echo "deb [arch=arm64] http://ports.ubuntu.com/ubuntu-ports focal-backports main restricted universe multiverse" >> /etc/apt/sources.list

RUN apt-get clean
RUN apt-get update -y

RUN echo "deb https://repo.download.nvidia.com/jetson/common r35.4 main" > /etc/apt/sources.list.d/nvidia-l4t-apt-source.list
RUN echo "deb https://repo.download.nvidia.com/jetson/t234 r35.4 main" >> /etc/apt/sources.list.d/nvidia-l4t-apt-source.list

RUN apt-get update -y

RUN apt-get install -y build-essential cmake git zsh vim wget pkg-config libssl-dev

RUN wget https://github.com/Kitware/CMake/releases/download/v3.18.6/cmake-3.18.6.tar.gz \
    && tar -zxvf cmake-3.18.6.tar.gz \
    && cd cmake-3.18.6 \
    && ./bootstrap && make -j$(nproc) && make install \
    && cd .. && rm -rf cmake-3.18.6 cmake-3.18.6.tar.gz

RUN git clone https://github.com/ggml-org/llama.cpp

RUN apt-get install -y ccache

WORKDIR /charlie/llama.cpp

# Debug: Find where libcuda actually is and save to file
RUN echo "=== Searching for libcuda ===" > /tmp/cuda-debug.txt && \
    find /usr -name "libcuda.so*" 2>/dev/null >> /tmp/cuda-debug.txt || echo "Not found with find" >> /tmp/cuda-debug.txt && \
    ldconfig -p | grep libcuda >> /tmp/cuda-debug.txt || echo "Not in ldconfig cache" >> /tmp/cuda-debug.txt && \
    ls -la /usr/lib/aarch64-linux-gnu/ | grep cuda >> /tmp/cuda-debug.txt || echo "Not in aarch64-linux-gnu" >> /tmp/cuda-debug.txt && \
    ls -la /usr/local/cuda/lib64/ 2>/dev/null | grep cuda >> /tmp/cuda-debug.txt || echo "Not in cuda/lib64" >> /tmp/cuda-debug.txt && \
    ls -la /usr/local/cuda/targets/aarch64-linux/lib/ 2>/dev/null | grep libcuda >> /tmp/cuda-debug.txt || echo "Not in targets" >> /tmp/cuda-debug.txt && \
    cat /tmp/cuda-debug.txt

RUN cmake -B build -DGGML_CUDA=ON \
      		   -DLLAMA_CURL=OFF \
                   -DCMAKE_CUDA_COMPILER=/usr/local/cuda-11.4/bin/nvcc \
 		   -DCMAKE_C_COMPILER_LAUNCHER=ccache \
                   -DCMAKE_CXX_COMPILER_LAUNCHER=ccache \
		   # This tells the linker to look here during build time, which directly embeds these paths into the shared object files which means you don't need
		   # to set LD_LIBRARY_PATH environment variable which is used during runtime
		   -DCMAKE_SHARED_LINKER_FLAGS="-L/usr/lib/aarch64-linux-gnu -Wl,-rpath,/usr/local/cuda/lib64 -Wl,-rpath,/usr/lib/aarch64-linux-gnu" \
    		   -DCMAKE_EXE_LINKER_FLAGS="-L/usr/lib/aarch64-linux-gnu -Wl,-rpath,/usr/local/cuda/lib64 -Wl,-rpath,/usr/lib/aarch64-linux-gnu" \
    && cmake --build build --config Release -j$(nproc)

#FROM ubuntu:20.04

#ENV CMAKE_VERISON=3.18

#RUN echo "Installing and building llama.cpp"

#RUN apt-get update -y
#RUN apt-get upgrade -y

#ENV DEBIAN_FRONTEND=noninteractive

# To build llama.cpp, you need cmake 3.18
#RUN apt-get install wget build-essential pkg-config libssl-dev git -y \
#       && wget https://github.com/Kitware/CMake/releases/download/v3.18.6/cmake-3.18.6.tar.gz \
#       && tar -zxvf cmake-3.18.6.tar.gz \
#       && cd cmake-3.18.6 \
#       && ./bootstrap && make -j$(nproc) && make install \
#       && cd .. && rm -rf cmake-3.18.6 cmake-3.18.6.tar.gz

#WORKDIR /workspace

#RUN git clone https://github.com/ggml-org/llama.cpp

#ENV DCMAKE_CUDA_COMPILER=/usr/local/cuda-11.4/bin/nvcc

# for cuda build of llama.cpp
#WORKDIR /workspace/llama.cpp
#RUN cmake -B build -DGGML_CUDA=ON -DLLAMA_CURL=OFF -DCMAKE_CUDA_COMPILER=/usr/local/cuda-11.4/bin/nvcc
#RUN cmake -B build -DGGML_CUDA=ON -DLLAMA_CURL=OFF
#RUN cmake --build build --config Release

